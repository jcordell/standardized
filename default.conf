[default]
data_path = DBTT_Data20.csv
save_path = ../DBTT/graphs/{}.png
lwr_data_path = CD_LWR_clean8.csv
X = N(Cu),N(Ni),N(Mn),N(P),N(Si),N( C ),N(log(fluence),N(log(flux),N(Temp)
Y = delta sigma
#whether or not the weights column in the dataset is applied which duplicates weighted data
weights = True

#The name of the program that creates the model, there should be a get() function in this file which returns the model
model = gkrr_model
test_cases = ErrorBias,DescriptorImportance,KFold_CV,LeaveOutAlloyCV,FullFit,FluenceFluxExtrapolation

#The configuration for AllTests.py
[AllTests]
data_path = ${default:data_path}
save_path = ${default:save_path}
lwr_data_path = ${default:lwr_data_path}
weights = ${default:weights}
X = ${default:X}
Y = ${default:Y}
model = linear_model

#list of all the tests you need, name should be exactly same as the file name.
#The execute() function of each file will be called
test_cases = ${default:test_cases}

#if some test files have different configuration setting than AllTests, you can make changes by adding a
#separate section
[LeaveOutAlloyCV]
save_path = ../DBTT/graphs/leaveoutAlloy/{}.png

[dtr_model]
max_depth = 5
min_samples_split = 2
min_samples_leaf = 1
split criterion = mse

[gkrr_model]
alpha = 0.00139
coef0 = 1
degree = 3
gamma = 0.518
kernel = rbf

[lkrr_model]
alpha = 0.00518
gamma = 0.518
kernel = laplacian

[randomforest_model]
estimators = 100
max_depth = 5
min_samples_split = 2
min_samples_leaf = 1
max_leaf_nodes = None
jobs = 1

[adaboost_model]
estimators = 275
max_depth = 12
min_samples_split = 2
min_samples_leaf = 1
learning rate = 1
loss function = linear

#minmax, size, transfer_function are the verbatim arguments for neurolab.net.newff()
#training_algorithm is the verbatim 'support train fcn' for neurolab.train omitting 'train_'
#see: https://pythonhosted.org/neurolab/lib.html#module-neurolab.net
#epochs,show,goal are neurolab.net.train() arguments
#see: https://pythonhosted.org/neurolab/lib.html#train-algorithms-based-gradients-algorithms
#NOTE: minmax is verbose b/c [[0,1]]*9 will have bad pointers
[nn_model]
minmax = [[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1],[0, 1]]
size = [11,1]
transfer_function = TanSig
training_algorithm = bfgs
epochs = 5
show = False
goal = 0.01

#keras
[keras_model]
epochs = 10000
learning_rate = .0005
hidden1 = 20
hidden2 = 10
hidden3 = 10
batch_size = 1500
num_ensemble = 10
savepath = ../DBTT/modelSaves/{}
